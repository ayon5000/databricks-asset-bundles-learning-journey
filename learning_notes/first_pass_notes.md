Contains timestamps recordedduring first pass of learning. This may or may not align with the structure of the course available today.

Date | Section | Video Name | Timestamp | Concept | Code/Tool | Notes |
| -- | -- | -- | -- | -- | -- | -- |
2025-08-30 | 2 | Azure Databricks Workspace Setup | [1:42] | Azure DB resource group and workspace setup for all 3 environments | | |
2025-08-30 | 2 | Azure Databricks Workspace Setup | [4:30] | Same UC metastore created for all 3 workspaces in the same region  | | |
2025-08-30 | 2 | VS Code | [1:05] | Databricks extension installation in VS Code | VS Code |  |
2025-08-30 | 2 | VS Code: Tutorial | N/A | Link to VS Code guide Includes some shortcuts that can be reviewed | VS Code | [Link](https://code.visualstudio.com/docs/introvideos/basics) |
2025-09-01 | 2 | Local Java Installation | All | Spark / Java Compatibility, Mapping DB Runtime to specific Java version required | Check java version installed: java --version | - To work with Databricks locally, you will need Java installed.<br/> - Go to [Link](https://learn.microsoft.com/en-us/azure/databricks/release-notes/runtime/) to check the current LTS version (check non-ML) and the version of Spark associated with it. <br/>- Once you have identified the Spark version, go to this [Link](https://community.cloudera.com/t5/Community-Articles/Spark-and-Java-versions-Supportability-Matrix/ta-p/383669) to check Spark-Java version mapping and identify the java version that needs to be installed.<br/> -In case the Spark-Java mapping is not available, go to the [Spark Homepage](https://spark.apache.org/docs/3.5.2/) for the specific version (***make sure you change the Spark version in the link***) and get the Java version for installation.<br/> - [Java Downloads Page](https://www.oracle.com/java/technologies/downloads/?er=221886)<br/> - **NOTE:** When we talk about Java Installation, we are talking about JDK installation, not JRE installation.<br/> - **Example:** Latest LTS DBR (Databricks Runtime) as of today is Databricks Runtime 16.4 LTS ML. The Databricks Runtime 16.4 LTS is powered by powered by Apache Spark 3.5.2, but we are unable to locate the corresponding Java version at [Link](https://community.cloudera.com/t5/Community-Articles/Spark-and-Java-versions-Supportability-Matrix/ta-p/383669). So, we look at [Spark Homepage](https://spark.apache.org/docs/3.5.2/) to find out in the Downloads section that "Spark runs on Java 8/11/17".<br/>  - In case you multiple versions of Java installed? - Set PATH for relevant version |
2025-09-01 | 2 | Python Installation | All | Python Installation for working with Databrciks on Local System | Python | You need to install the Python version associated with the Databricks runtime. In order to check the Python version required, go to the [Microsoft page listing the DBRs](https://learn.microsoft.com/en-us/azure/databricks/release-notes/runtime/), go to the specific DBR, on the right you will find a section called 'System environment', check on it and you should be able to see the Python version listed. Please note that we just need to align the major and minor version i.e. Databricks Runtime 16.4 LTS is associated with Python: 3.12.3. Having Python: 3.12.x installed will suffice where x is a non-negative integer |
2025-09-01 | 2 | Databricks CLI | [0:15] | - Install Databricks CLI using curl<br/> - Current curl command for installation: ```curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh \| sh``` | To check Databricks CLI version:<br/> - databricks --version | - Check this [link](https://learn.microsoft.com/en-us/azure/databricks/dev-tools/cli/install) for installation with curl.<br/> - For Linux and macOS, if an error message states that /usr/local/bin is not writable, then run the command again with sudo i.e. add sudo infront of each piped command e.g. ```sudo curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh \| sudo sh``` |